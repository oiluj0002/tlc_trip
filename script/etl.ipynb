{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_credentials = service_account.Credentials.from_service_account_file('../.env/storage_credentials.json')\n",
    "bigquery_credentials = service_account.Credentials.from_service_account_file('../.env/bigquery_credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob(bucket, blob, destination):\n",
    "    \"\"\"Downloads a blob from the bucket.\n",
    "    - bucket_name: nome do bucket no GCP\n",
    "    - source_blob_name: nome do arquivo a baixar\n",
    "    - destination: destino\"\"\"\n",
    "\n",
    "    storage_client = storage.Client(credentials=storage_credentials)\n",
    "\n",
    "    bucket = storage_client.bucket(bucket)\n",
    "\n",
    "    blob = bucket.blob(blob)\n",
    "    blob.download_to_filename(destination)\n",
    "\n",
    "    print(\n",
    "        \"Download do arquivo {} do bucket {} para diretório {}.\".format(\n",
    "            blob, bucket, destination\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download do arquivo <Blob: tlc-trip-bronze, data.parquet, 1722093615910258> do bucket <Bucket: tlc-trip-bronze> para diretório ../bronze/data.parquet.\n",
      "Download do arquivo <Blob: tlc-trip-bronze, taxi_zone.csv, 1722093597014586> do bucket <Bucket: tlc-trip-bronze> para diretório ../bronze/taxi_zone.csv.\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('../bronze')\n",
    "download_blob('tlc-trip-bronze', 'data.parquet', '../bronze/data.parquet')\n",
    "download_blob('tlc-trip-bronze', 'taxi_zone.csv', '../bronze/taxi_zone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pq.read_table('../bronze/data.parquet')\n",
    "df_taxi_zone = pd.read_csv('../bronze/taxi_zone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = table.to_pandas()\n",
    "\n",
    "codigo_tarifa = pd.DataFrame(df_data['RatecodeID']).rename(columns={'RatecodeID': 'id_codigo_tarifa'})\n",
    "flag = pd.DataFrame(df_data['store_and_fwd_flag']).rename(columns={'store_and_fwd_flag': 'id_flag'})\n",
    "tipo_pagamento = pd.DataFrame(df_data['payment_type']).rename(columns={'payment_tipe': 'id_tipo_pagamento'})\n",
    "provedor = pd.DataFrame(df_data['VendorID']).rename(columns={'VendorID': 'id_provedor'})\n",
    "id_inicio = pd.DataFrame(df_data['PULocationID'])\n",
    "local_inicio = pd.merge(id_inicio, df_taxi_zone, how='left', left_on='PULocationID', right_on='LocationID')\\\n",
    "                .drop(columns='LocationID')\\\n",
    "                .rename(columns={'PULocationID': 'id_local_inicio', 'Borough': 'bairro', 'Zone': 'zona', 'service_zone': 'zona_servico'})\n",
    "id_termino = pd.DataFrame(df_data['DOLocationID'])\n",
    "local_termino = pd.merge(id_termino, df_taxi_zone, how='left', left_on='DOLocationID', right_on='LocationID')\\\n",
    "                .drop(columns='LocationID')\\\n",
    "                .rename(columns={'DOLocationID': 'id_local_termino', 'Borough': 'bairro', 'Zone': 'zona', 'service_zone': 'zona_servico'})\n",
    "calendario = pd.DataFrame(df_data[['tpep_pickup_datetime', 'tpep_dropoff_datetime']])\\\n",
    "                .rename(columns={'tpep_pickup_datetime': 'inicio_datetime', 'tpep_dropoff_datetime': 'termino_datetime'})\n",
    "viagens = df_data.drop(columns='total_amount').rename(columns={\n",
    "    'VendorID': 'id_provedor',\n",
    "    'tpep_pickup_datetime': 'inicio_datetime',\n",
    "    'tpep_dropoff_datetime': 'termino_datetime', \n",
    "    'passenger_count': 'qtd_passageiros',\n",
    "    'trip_distance': 'distancia',\n",
    "    'RatecodeID': 'id_codigo_tarifa',\n",
    "    'store_and_fwd_flag': 'id_flag',\n",
    "    'PULocationID': 'id_local_inicio',\n",
    "    'DOLocationID': 'id_local_termino',\n",
    "    'payment_type': 'tipo_pagamento',\n",
    "    'fare_amount': 'vlr_tarifa',\n",
    "    'extra': 'vlr_extra',\n",
    "    'mta_tax': 'vlr_tributo_mta',\n",
    "    'tip_amount': 'vlr_gorgeta',\n",
    "    'tolls_amount': 'vlr_pedagio',\n",
    "    'improvement_surcharge': 'vlr_sobretaxa_melhoria',\n",
    "    'congestion_surcharge': 'vlr_sobretaxa_congestionamento',\n",
    "    'Airport_fee': 'vlr_tarifa_aeroporto'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(credentials=bigquery_credentials, project=bigquery_credentials.project_id)\n",
    "dataset = bigquery.Dataset(f'{client.project}.silver')\n",
    "dataset = client.create_dataset(dataset, exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela \"codigo_tarifa\" carregada com sucesso\n",
      "Tabela \"flag\" carregada com sucesso\n",
      "Tabela \"tipo_pagamento\" carregada com sucesso\n",
      "Tabela \"provedor\" carregada com sucesso\n",
      "Tabela \"local_inicio\" carregada com sucesso\n",
      "Tabela \"local_termino\" carregada com sucesso\n",
      "Tabela \"calendario\" carregada com sucesso\n",
      "Tabela \"viagens\" carregada com sucesso\n"
     ]
    }
   ],
   "source": [
    "export = {\n",
    "    'codigo_tarifa': codigo_tarifa, \n",
    "    'flag': flag, \n",
    "    'tipo_pagamento': tipo_pagamento, \n",
    "    'provedor': provedor, \n",
    "    'local_inicio': local_inicio, \n",
    "    'local_termino': local_termino, \n",
    "    'calendario': calendario, \n",
    "    'viagens': viagens\n",
    "    }\n",
    "\n",
    "for table_name, table in export.items():\n",
    "    table_id = f'{client.project}.{dataset.dataset_id}.silver_{table_name}'\n",
    "    job = client.load_table_from_dataframe(table, table_id)\n",
    "    job.result()\n",
    "    print(f'Tabela \"{table_name}\" carregada com sucesso')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
